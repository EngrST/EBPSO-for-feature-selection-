{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An enhanced particle swarm optimization with position update for optimal        feature selection\n",
    "## Sani Tijjani,  Mohd Nadhir Ab Wahab and  Mohd Halim Mohd Noor,\n",
    "\n",
    "### School of Computer Sciences, Universiti Sains Malaysia, 11800 USM Pulau Pinang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.44</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.05587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.20850</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.49</td>\n",
       "      <td>18.61</td>\n",
       "      <td>66.86</td>\n",
       "      <td>334.3</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.02297</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>...</td>\n",
       "      <td>24.54</td>\n",
       "      <td>70.76</td>\n",
       "      <td>375.4</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.06528</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.07842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>70.79</td>\n",
       "      <td>365.6</td>\n",
       "      <td>0.09687</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.02788</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06408</td>\n",
       "      <td>...</td>\n",
       "      <td>26.51</td>\n",
       "      <td>76.43</td>\n",
       "      <td>407.5</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.81</td>\n",
       "      <td>23.75</td>\n",
       "      <td>91.56</td>\n",
       "      <td>597.8</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>0.17680</td>\n",
       "      <td>0.15580</td>\n",
       "      <td>0.09176</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>...</td>\n",
       "      <td>41.85</td>\n",
       "      <td>128.50</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.46460</td>\n",
       "      <td>0.20130</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.46</td>\n",
       "      <td>20.11</td>\n",
       "      <td>109.30</td>\n",
       "      <td>832.9</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.17930</td>\n",
       "      <td>0.08866</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.06323</td>\n",
       "      <td>...</td>\n",
       "      <td>28.45</td>\n",
       "      <td>123.50</td>\n",
       "      <td>981.2</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.58620</td>\n",
       "      <td>0.20350</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.09519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2      3        4        5        6        7       8   \\\n",
       "0  13.44  21.58   86.18  563.0  0.08162  0.06031  0.03110  0.02031  0.1784   \n",
       "1  10.49  18.61   66.86  334.3  0.10680  0.06678  0.02297  0.01780  0.1482   \n",
       "2  10.96  17.62   70.79  365.6  0.09687  0.09752  0.05263  0.02788  0.1619   \n",
       "3  13.81  23.75   91.56  597.8  0.13230  0.17680  0.15580  0.09176  0.2251   \n",
       "4  16.46  20.11  109.30  832.9  0.09831  0.15560  0.17930  0.08866  0.1794   \n",
       "\n",
       "        9   ...     21      22      23      24      25       26       27  \\\n",
       "0  0.05587  ...  30.25  102.50   787.9  0.1094  0.2043  0.20850  0.11120   \n",
       "1  0.06600  ...  24.54   70.76   375.4  0.1413  0.1044  0.08423  0.06528   \n",
       "2  0.06408  ...  26.51   76.43   407.5  0.1428  0.2510  0.21230  0.09861   \n",
       "3  0.07421  ...  41.85  128.50  1153.0  0.2226  0.5209  0.46460  0.20130   \n",
       "4  0.06323  ...  28.45  123.50   981.2  0.1415  0.4667  0.58620  0.20350   \n",
       "\n",
       "       28       29  30  \n",
       "0  0.2994  0.07146   1  \n",
       "1  0.2213  0.07842   2  \n",
       "2  0.2289  0.08278   2  \n",
       "3  0.4432  0.10860   1  \n",
       "4  0.3054  0.09519   1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data=pandas.read_csv('C:/Users/Engr. Dr Sani Tijjan/Desktop/Experiment E/Experiments/UCIcsv/BreastEW.csv',header=None)#header=None\n",
    "header=None \n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.44</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.05587</td>\n",
       "      <td>...</td>\n",
       "      <td>30.25</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.20850</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.49</td>\n",
       "      <td>18.61</td>\n",
       "      <td>66.86</td>\n",
       "      <td>334.3</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.02297</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>...</td>\n",
       "      <td>24.54</td>\n",
       "      <td>70.76</td>\n",
       "      <td>375.4</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.06528</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.07842</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>70.79</td>\n",
       "      <td>365.6</td>\n",
       "      <td>0.09687</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.02788</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06408</td>\n",
       "      <td>...</td>\n",
       "      <td>26.51</td>\n",
       "      <td>76.43</td>\n",
       "      <td>407.5</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.81</td>\n",
       "      <td>23.75</td>\n",
       "      <td>91.56</td>\n",
       "      <td>597.8</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>0.17680</td>\n",
       "      <td>0.15580</td>\n",
       "      <td>0.09176</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>...</td>\n",
       "      <td>41.85</td>\n",
       "      <td>128.50</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.46460</td>\n",
       "      <td>0.20130</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.46</td>\n",
       "      <td>20.11</td>\n",
       "      <td>109.30</td>\n",
       "      <td>832.9</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.17930</td>\n",
       "      <td>0.08866</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.06323</td>\n",
       "      <td>...</td>\n",
       "      <td>28.45</td>\n",
       "      <td>123.50</td>\n",
       "      <td>981.2</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.58620</td>\n",
       "      <td>0.20350</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.09519</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1       2      3        4        5        6        7       8   \\\n",
       "0  13.44  21.58   86.18  563.0  0.08162  0.06031  0.03110  0.02031  0.1784   \n",
       "1  10.49  18.61   66.86  334.3  0.10680  0.06678  0.02297  0.01780  0.1482   \n",
       "2  10.96  17.62   70.79  365.6  0.09687  0.09752  0.05263  0.02788  0.1619   \n",
       "3  13.81  23.75   91.56  597.8  0.13230  0.17680  0.15580  0.09176  0.2251   \n",
       "4  16.46  20.11  109.30  832.9  0.09831  0.15560  0.17930  0.08866  0.1794   \n",
       "\n",
       "        9   ...     21      22      23      24      25       26       27  \\\n",
       "0  0.05587  ...  30.25  102.50   787.9  0.1094  0.2043  0.20850  0.11120   \n",
       "1  0.06600  ...  24.54   70.76   375.4  0.1413  0.1044  0.08423  0.06528   \n",
       "2  0.06408  ...  26.51   76.43   407.5  0.1428  0.2510  0.21230  0.09861   \n",
       "3  0.07421  ...  41.85  128.50  1153.0  0.2226  0.5209  0.46460  0.20130   \n",
       "4  0.06323  ...  28.45  123.50   981.2  0.1415  0.4667  0.58620  0.20350   \n",
       "\n",
       "       28       29  30  \n",
       "0  0.2994  0.07146   1  \n",
       "1  0.2213  0.07842   2  \n",
       "2  0.2289  0.08278   2  \n",
       "3  0.4432  0.10860   1  \n",
       "4  0.3054  0.09519   1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=Data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={ data.columns[30]: \"Class\" }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    357\n",
       "1    211\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>Class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.44</td>\n",
       "      <td>21.58</td>\n",
       "      <td>86.18</td>\n",
       "      <td>563.0</td>\n",
       "      <td>0.08162</td>\n",
       "      <td>0.06031</td>\n",
       "      <td>0.03110</td>\n",
       "      <td>0.02031</td>\n",
       "      <td>0.1784</td>\n",
       "      <td>0.05587</td>\n",
       "      <td>...</td>\n",
       "      <td>102.50</td>\n",
       "      <td>787.9</td>\n",
       "      <td>0.1094</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>0.20850</td>\n",
       "      <td>0.11120</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.07146</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.49</td>\n",
       "      <td>18.61</td>\n",
       "      <td>66.86</td>\n",
       "      <td>334.3</td>\n",
       "      <td>0.10680</td>\n",
       "      <td>0.06678</td>\n",
       "      <td>0.02297</td>\n",
       "      <td>0.01780</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.06600</td>\n",
       "      <td>...</td>\n",
       "      <td>70.76</td>\n",
       "      <td>375.4</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.08423</td>\n",
       "      <td>0.06528</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>0.07842</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.96</td>\n",
       "      <td>17.62</td>\n",
       "      <td>70.79</td>\n",
       "      <td>365.6</td>\n",
       "      <td>0.09687</td>\n",
       "      <td>0.09752</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.02788</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06408</td>\n",
       "      <td>...</td>\n",
       "      <td>76.43</td>\n",
       "      <td>407.5</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>0.21230</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.2289</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.81</td>\n",
       "      <td>23.75</td>\n",
       "      <td>91.56</td>\n",
       "      <td>597.8</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>0.17680</td>\n",
       "      <td>0.15580</td>\n",
       "      <td>0.09176</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>...</td>\n",
       "      <td>128.50</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.46460</td>\n",
       "      <td>0.20130</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.10860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.46</td>\n",
       "      <td>20.11</td>\n",
       "      <td>109.30</td>\n",
       "      <td>832.9</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.17930</td>\n",
       "      <td>0.08866</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.06323</td>\n",
       "      <td>...</td>\n",
       "      <td>123.50</td>\n",
       "      <td>981.2</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.58620</td>\n",
       "      <td>0.20350</td>\n",
       "      <td>0.3054</td>\n",
       "      <td>0.09519</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2      3        4        5        6        7       8  \\\n",
       "0  13.44  21.58   86.18  563.0  0.08162  0.06031  0.03110  0.02031  0.1784   \n",
       "1  10.49  18.61   66.86  334.3  0.10680  0.06678  0.02297  0.01780  0.1482   \n",
       "2  10.96  17.62   70.79  365.6  0.09687  0.09752  0.05263  0.02788  0.1619   \n",
       "3  13.81  23.75   91.56  597.8  0.13230  0.17680  0.15580  0.09176  0.2251   \n",
       "4  16.46  20.11  109.30  832.9  0.09831  0.15560  0.17930  0.08866  0.1794   \n",
       "\n",
       "         9  ...      22      23      24      25       26       27      28  \\\n",
       "0  0.05587  ...  102.50   787.9  0.1094  0.2043  0.20850  0.11120  0.2994   \n",
       "1  0.06600  ...   70.76   375.4  0.1413  0.1044  0.08423  0.06528  0.2213   \n",
       "2  0.06408  ...   76.43   407.5  0.1428  0.2510  0.21230  0.09861  0.2289   \n",
       "3  0.07421  ...  128.50  1153.0  0.2226  0.5209  0.46460  0.20130  0.4432   \n",
       "4  0.06323  ...  123.50   981.2  0.1415  0.4667  0.58620  0.20350  0.3054   \n",
       "\n",
       "        29  Class  label  \n",
       "0  0.07146      1      0  \n",
       "1  0.07842      2      1  \n",
       "2  0.08278      2      1  \n",
       "3  0.10860      1      0  \n",
       "4  0.09519      1      0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "data['label']=label.fit_transform(data['Class'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    211\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Class','label'], axis=1).copy()\n",
    "#X = data.drop(['Code','Class','label'], axis=1).copy()\n",
    "y = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568, 32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionslity reduction mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:    (568, 30)\n",
      "transformed shape: (568, 12)\n"
     ]
    }
   ],
   "source": [
    "Fs = data.shape[0]\n",
    "n =12\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = n)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "print(\"original shape:   \", X.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)\n",
    "#X=X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ft_Accuracy: 95.614\n",
      "original shape:    (568, 30)\n",
      "Fr_Accuracy: 94.737\n",
      "transformed shape: (568, 12)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "Ft = X\n",
    "Fr = X_pca\n",
    "\n",
    "\n",
    "#Ft_accuracy\n",
    "X=Ft\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "model_Ft = KNeighborsClassifier(leaf_size=1, n_neighbors=1, algorithm='auto', p=1)#n_neighbor\n",
    "model_Ft.fit(X_train, y_train)\n",
    "predictions1 = model_Ft.predict(X_test)\n",
    "score_Ft = accuracy_score(y_test, predictions1)\n",
    "print('Ft_Accuracy: %.3f' % (score_Ft*100))\n",
    "print(\"original shape:   \", X.shape)\n",
    "\n",
    "\n",
    "#Fr_accuracy\n",
    "X=Fr\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "model_Fr = KNeighborsClassifier(leaf_size=1, n_neighbors=1, algorithm='auto', p=1)#n_neighbor\n",
    "model_Fr.fit(X_train, y_train)\n",
    "predictions2 = model_Fr.predict(X_test)\n",
    "score_Fr = accuracy_score(y_test, predictions2)\n",
    "print('Fr_Accuracy: %.3f' % (score_Fr*100))\n",
    "print(\"transformed shape:\", X_pca.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Fr\n",
    "nf = (Fr.shape[1])\n",
    "nf2 = (Ft.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data spltiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions: (454, 12)\n",
      "y_train dimensions: (454,)\n",
      "\n",
      "X_test dimensions: (114, 12)\n",
      "y_test dimensions: (114,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from numpy import concatenate\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from time import time\n",
    "\n",
    "# split into train and test (80% : 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "\n",
    "# Check dimensions of data after splitting\n",
    "\n",
    "print(f\"X_train dimensions: {X_train.shape}\")\n",
    "print(f\"y_train dimensions: {y_train.shape}\\n\")\n",
    "\n",
    "print(f\"X_test dimensions: {X_test.shape}\")\n",
    "print(f\"y_test dimensions: {y_test.shape}\\n\")\n",
    "\n",
    "#print(f\"X_val dimensions: {X_val.shape}\")\n",
    "#print(f\"y_val dimensions: {y_val.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "leaf_size = list(range(1,50))\n",
    "n_neighbors =list(range(1,30))\n",
    "p=[1,2]\n",
    "\n",
    "hyperparameters = dict(leaf_size=leaf_size,n_neighbors=n_neighbors, p=p)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "clf = GridSearchCV(KNeighborsClassifier(), hyperparameters, cv=10)\n",
    "best_model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best leaf_size: 1\n",
      "Best n_neighbors: 11\n",
      "Best p: 1\n"
     ]
    }
   ],
   "source": [
    "print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of hyperparametertuned KNN: 94.737\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model1 = KNeighborsClassifier(leaf_size=1, n_neighbors=1, algorithm='auto', p=1)#n_neighbor\n",
    "\n",
    "start = time()\n",
    "model1.fit(X_train, y_train)\n",
    "end = time()\n",
    "\n",
    "# make predictions on hold out test set\n",
    "predictions1 = model1.predict(X_test)\n",
    "\n",
    "score1 = accuracy_score(y_test, predictions1)\n",
    "print('Accuracy of hyperparametertuned KNN: %.3f' % (score1*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enhanced BPSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import random\n",
    "from random import random,randint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import seaborn as sns # data visualization library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "class BPSO:\n",
    "    def __init__(self, f_count, df):\n",
    "        \n",
    "        #feature count \n",
    "        self.f_count  = f_count\n",
    "        # Actual Positions  radmon prob\n",
    "        self.pos_act  = []\n",
    "        # Position prob > 0.5 set as 1 or 0  \n",
    "        self.position = []\n",
    "        # Velocity random between -1 and 1 \n",
    "        self.velocity = []\n",
    "        # best position \n",
    "        self.pos_best = []\n",
    "        # Y actual \n",
    "        self.y_actual = []\n",
    "        # Y test predicted \n",
    "        self.y_predict= []\n",
    "        # best fit accuracy, Recall, Precision\n",
    "        self.fit_best = (-1, -1, -1)\n",
    "        # accuracy , recall, precsion \n",
    "        self.fitness  = (-1, -1, -1)\n",
    "        # data \n",
    "        self.df       = df.copy()\n",
    "        \n",
    "        self.initialize(f_count)\n",
    "        #M=0.7\n",
    "    \n",
    "    # initialize \n",
    "    def initialize(self, f_count):\n",
    "        self.f_count = f_count\n",
    "        self.initalize_position(f_count)\n",
    "        self.initialize_velocity(f_count)\n",
    "    \n",
    "    def set_data(self,data):\n",
    "        self.df = data.copy()\n",
    "        print(self.df.head())\n",
    "        \n",
    "    #Initialize the positions > 0.5  is set as 1\n",
    "    def initalize_position(self,f_count):\n",
    "        self.pos_act = np.random.uniform(low=0, high=1, size=f_count).tolist()\n",
    "        self.position = [1 if po > 0.5 else 0  for po in self.pos_act]\n",
    "        \n",
    "    def initialize_velocity(self, f_count):\n",
    "        self.velocity = np.random.uniform(low=-1, high=1, size=f_count).tolist()\n",
    "        \n",
    "    \n",
    "    def drop_columns(self, X):\n",
    "        print(X.shape)\n",
    "        print(self.position)\n",
    "        for index, value in enumerate(self.position):\n",
    "            if value == 0 :\n",
    "                X_1 = X.drop(X.columns[index], axis = 1)\n",
    "        return X_1\n",
    "    \n",
    "    def classification_accuracy(self,y_actual, y_hat):\n",
    "        \n",
    "        cnf_matrix = confusion_matrix(y_actual, y_hat)\n",
    "        \n",
    "        FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "        FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "        TP = np.diag(cnf_matrix)\n",
    "        TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "        \n",
    "        #class_acc = (TP+TN) / (TP+FP+TN+FN)\n",
    "        class_acc = sum(TP)/(TP+FP+TN+FN)\n",
    "        precision = (TP) / ( TP + FP )  \n",
    "        sensitivity =  (TP)/ (TP+FN)\n",
    "        specificity =(sum(TP)-TP)/((sum(TP)-TP)+FP)\n",
    "        \n",
    "        return (class_acc,precision,sensitivity,specificity)\n",
    "        \n",
    "    \n",
    "    def process_data(self):\n",
    "        \n",
    "        # Spilt the train and test data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        # we used 30% test data\n",
    "        # check the size before beginning\n",
    "        X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "    \n",
    "        model1 = KNeighborsClassifier(leaf_size=1, n_neighbors=1, algorithm='auto', p=1)\n",
    "        #start = time()\n",
    "        model1.fit(X_train, y_train)\n",
    "        #end = time()\n",
    "        y_pred = model1.predict(X_test)\n",
    "        \n",
    "        # find accuracy\n",
    "        ac = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        class_acc = self.classification_accuracy(y_test, y_pred)\n",
    "        \n",
    "        self.y_actual = y_test\n",
    "        self.y_predict = y_pred\n",
    "         \n",
    "        return class_acc\n",
    "    \n",
    "    \n",
    "    def fitness_check(self,fitness, fit_best):\n",
    "        is_fitness = False\n",
    "        \n",
    "        if (fitness[0][:, None] > fit_best[0]).any() or (fit_best[0] == -1).any():\n",
    "            if (fitness[1][:, None] >= fit_best[1]).any() and (fitness[2][:, None] >= fit_best[2]).any():\n",
    "                is_fitness = True\n",
    "        \n",
    "        return is_fitness\n",
    "\n",
    "    #evaluate the fitness\n",
    "    def evaluate_fitness(self):\n",
    "        self.fitness = self.process_data()\n",
    "        \n",
    "        if  self.fitness_check(self.fitness, self.fit_best):\n",
    "            self.pos_best  = self.position.copy()\n",
    "            self.fit_best = self.fitness\n",
    "    \n",
    "    def update_velocity(self, pos_best_global):\n",
    "        \n",
    "        c1 = 0.5 \n",
    "        c2 = 1 \n",
    "        w  = 0.5  \n",
    "       \n",
    "        for i in range(0, self.f_count):\n",
    "            r1 = np.random.uniform(low=-1, high=1, size=1)[0]\n",
    "            r2 = np.random.uniform(low=-1, high=1, size=1)[0]\n",
    "            velocity_cog = c1*r1*(self.pos_best[i]-self.position[i])\n",
    "            velocity_soc = c2*r2*(pos_best_global[i]-self.position[i])\n",
    "            \n",
    "            self.velocity[i]=w*self.velocity[i]+velocity_cog+velocity_soc\n",
    "            \n",
    "    def update_position(self):\n",
    "        \n",
    "        for i in range(0, self.f_count):\n",
    "            self.pos_act[i] = (self.pos_act[i]) + (self.velocity[i])\n",
    "            \n",
    "            #adjust max value \n",
    "            \n",
    "            if self.pos_act[i] > 1:\n",
    "                self.pos_act[i] = 0.9\n",
    "            \n",
    "            if self.pos_act[i] < 0 :\n",
    "                self.pos_act[i] = 0.0\n",
    "                \n",
    "            #EPSO1    \n",
    "            self.position[i] = 1 if self.pos_act[i] > 0.5 else 0 \n",
    "            \n",
    "            #Standard binary PSO\n",
    "            #S = expit(-(self.velocity[i]))\n",
    "            #rn = np.random.uniform(low=0, high=1, size=1)[0]  \n",
    "            #self.position[i] = 0 if rn > S else 1\n",
    "        \n",
    "            #EPSO2\n",
    "            #S = expit(-(self.pos_act[i]))\n",
    "            #self.position[i] = 1 if S > 0.5 else 1\n",
    "          \n",
    "    def print_position(self):\n",
    "        print(self.position)\n",
    "    \n",
    "    def print_velocity(self):\n",
    "        print(self.velocity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso_calculate(f_count, df):\n",
    "    y_actual = []\n",
    "    y_predict = []\n",
    "    #fitness_best_g = (0, 0, 0)\n",
    "    fitness_best_g = (-1, -1, -1)\n",
    "    pos_fitness_g = []\n",
    "    swarm = []\n",
    "    no_population = 20\n",
    "    \n",
    "    selected_fetures = (sum((pos_fitness_g)*1)) / ((len(pos_fitness_g))+1)\n",
    "    \n",
    "    for i in range(0,no_population):\n",
    "        swarm.append(BPSO(f_count, df))\n",
    "    \n",
    "    #optimize \n",
    "    index = 0\n",
    "    \n",
    "    while index < 100:\n",
    "        \n",
    "        for pos in range(0, no_population):\n",
    "            swarm[pos].evaluate_fitness()\n",
    "            \n",
    "            #check current particle is the global best \n",
    "            if swarm[pos].fitness_check(swarm[pos].fitness, fitness_best_g):\n",
    "                pos_fitness_g = list(swarm[pos].position)\n",
    "                fitness_best_g = (swarm[pos].fitness)\n",
    "                y_actual = swarm[pos].y_actual\n",
    "                y_predict = swarm[pos].y_predict\n",
    "                \n",
    "        F_ratio = (sum((pos_fitness_g)*1)) / ((nf2))\n",
    "        Acc = (np.mean(fitness_best_g[0]))\n",
    "        E = (1 - Acc)\n",
    "        Fitness_Value = (0.99*E) + ((1 - 0.99)*F_ratio)\n",
    "             \n",
    "        print(\"Iteration:\", index + 1)\n",
    "        print(pos_fitness_g)\n",
    "        print(sum(pos_fitness_g))\n",
    "        print(Fitness_Value)\n",
    "        print(Acc)\n",
    "        \n",
    "        \n",
    "        for pos in range(0, no_population):\n",
    "        \n",
    "            swarm[pos].update_velocity(pos_fitness_g)\n",
    "            swarm[pos].update_position()\n",
    "            \n",
    "       # for pos in range(0, no_population):\n",
    "            \n",
    "            #selected_features1 = sum((pos_fitness_g)*1)\n",
    "            \n",
    "            #if ((np.mean(fitness_best_g)) > (np.mean(fitness_best_g))) and (selected_features1 <= selected_features1):\n",
    "                #pos_fitness_g = pos_fitness_g\n",
    "                #swarm[pos].update_position()\n",
    "               \n",
    "        index+=1\n",
    "    \n",
    "    end = time()\n",
    "    \n",
    "    \n",
    "    print('\\n Final Solution:')\n",
    "    print(pos_fitness_g)\n",
    "    print(fitness_best_g)\n",
    "    print('selected features = ' + str(sum((pos_fitness_g)*1)) + '/' + str(len(pos_fitness_g)))\n",
    "    print(\"Processing time is {:.4f} seconds\".format(end-start))\n",
    "    \n",
    "    from mlxtend.plotting import plot_confusion_matrix \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    \n",
    "    score3 = accuracy_score(y_actual, y_predict)\n",
    "    cm_ = confusion_matrix(y_actual, y_predict)\n",
    "    cm_4 =cm_/cm_.astype(np.float).sum(axis=1)\n",
    "    \n",
    "    cm_3 = confusion_matrix(y_actual, y_predict)\n",
    "    FP =  cm_3.sum(axis=0) - np.diag( cm_3) \n",
    "    FN =  cm_3.sum(axis=1) - np.diag( cm_3)\n",
    "    TP = np.diag( cm_3)\n",
    "    TN =  cm_3.sum() - (FP + FN + TP)\n",
    "        \n",
    "    #class_acc = ((TP+TN)) / ((TP+FP+TN+FN))\n",
    "    class_acc = sum(TP)/((TP+FP+TN+FN))\n",
    "    precision = (TP) / ( TP + FP )  \n",
    "    sensitivity =  (TP)/ (TP+FN) # recall\n",
    "    specificity =(sum(TP)-TP)/((sum(TP)-TP)+FP)\n",
    "    #specificity =  (TN)/ (TN+FP)\n",
    "    f1 = (2*((TP) / ( TP + FP ))*((TP)/ (TP+FN)))/ (((TP) / ( TP + FP ))+((TP)/ (TP+FN)))\n",
    "    \n",
    "    print('Fitness value : ' + str(Fitness_Value)) \n",
    "    print('Accuracy : ' + str(class_acc))               \n",
    "    print('Precision : ' + str(precision))\n",
    "    print('Recall/Sensitivity : ' + str(sensitivity))               \n",
    "    print('F1 : ' + str(f1))\n",
    "    print('Specificiity : ' + str(specificity[1]))\n",
    "    \n",
    "    \n",
    "    print('accuracy : ' + str((accuracy_score(y_actual, y_predict)*100)))\n",
    "    print('precision : ' + str((precision_score(y_actual, y_predict, average=\"macro\")*100)))\n",
    "    print('recall/sensitivity : ' + str((recall_score(y_actual, y_predict, average=\"macro\")*100)))\n",
    "    print('f1_score : ' + str((f1_score(y_actual, y_predict, average=\"macro\")*100)))\n",
    "    print('Specificiity : ' + str((specificity[1])*100))\n",
    "       \n",
    "\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "    def multiclass_roc_auc_score(y_actual, y_predict,*, average=\"macro\"):\n",
    "    \n",
    "        lb = LabelBinarizer()\n",
    "        lb.fit(y_actual)\n",
    "    \n",
    "        y_actual = lb.transform(y_actual)\n",
    "        y_predict = lb.transform(y_predict)\n",
    "    \n",
    "        return roc_auc_score(y_actual, y_predict, average=average)\n",
    "\n",
    "    AUC = multiclass_roc_auc_score(y_actual, y_predict)\n",
    "    print('AUC : ' + str(AUC*100))\n",
    "    #multiclass_roc_auc_score(y_actual, y_predict)\n",
    "    \n",
    "    #AUC2 = roc_auc_score(y_actual, y_predict)\n",
    "    #print('AUC2 : ' + str(AUC*100))\n",
    "    print('\\n Final Solution:')\n",
    "    print(pos_fitness_g)\n",
    "    print(fitness_best_g)\n",
    "    #end = time()\n",
    "    #print(\"Classifier fitted in {:.4f} seconds\".format(end-start))\n",
    "    sns.heatmap(cm_3,annot=True,fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 2\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 3\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 4\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 5\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 6\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 7\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 8\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 9\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 10\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 11\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 12\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 13\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 14\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 15\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 16\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 17\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 18\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "9\n",
      "0.01168421052631582\n",
      "0.9912280701754386\n",
      "Iteration: 19\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 20\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 21\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 22\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 23\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 24\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 25\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 26\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 27\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 28\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 29\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 30\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 31\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 32\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 33\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 34\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 35\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 36\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 37\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 38\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 39\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 40\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 41\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 42\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 43\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 44\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 45\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 46\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 47\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 48\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 49\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 50\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 51\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 52\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 53\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 54\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 55\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 56\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 57\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 58\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 59\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 60\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 61\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 62\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 63\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 64\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 65\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 66\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 67\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 68\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 69\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 70\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 71\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 72\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 73\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 74\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 75\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 76\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 77\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 78\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 79\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 80\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 81\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 82\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 83\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 84\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 85\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 86\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 87\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 88\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 89\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 90\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 91\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 92\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 93\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 94\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 95\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 96\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 97\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 98\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 99\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "Iteration: 100\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "5\n",
      "0.001666666666666668\n",
      "1.0\n",
      "\n",
      " Final Solution:\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "(array([1., 1.]), array([1., 1.]), array([1., 1.]), array([1., 1.]))\n",
      "selected features = 5/12\n",
      "Processing time is 44.2524 seconds\n",
      "Fitness value : 0.001666666666666668\n",
      "Accuracy : [1. 1.]\n",
      "Precision : [1. 1.]\n",
      "Recall/Sensitivity : [1. 1.]\n",
      "F1 : [1. 1.]\n",
      "Specificiity : 1.0\n",
      "accuracy : 100.0\n",
      "precision : 100.0\n",
      "recall/sensitivity : 100.0\n",
      "f1_score : 100.0\n",
      "Specificiity : 100.0\n",
      "AUC : 100.0\n",
      "\n",
      " Final Solution:\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "(array([1., 1.]), array([1., 1.]), array([1., 1.]), array([1., 1.]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = X\n",
    "#df['Unnamed: 32'] = 0\n",
    "pso_calculate(nf,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
